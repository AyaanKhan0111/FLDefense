{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05469abe",
   "metadata": {},
   "source": [
    "Muhammad Qasim 22I-1994 | Ayaan Khan 22I-2066 |\n",
    "Ahmed Luqman 22I-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057070d8",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e66755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU support not available, will use CPU/CUDA\n",
      "Libraries imported successfully!\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n",
      "TPU available: False\n",
      "Models will be saved to: ./saved_models/\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "from collections import defaultdict, namedtuple\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Try to import TPU support\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    TPU_AVAILABLE = True\n",
    "    print(\"TPU support detected!\")\n",
    "except ImportError:\n",
    "    TPU_AVAILABLE = False\n",
    "    print(\"TPU support not available, will use CPU/CUDA\")\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Create directory for saving models\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"TPU available: {TPU_AVAILABLE}\")\n",
    "print(f\"Models will be saved to: ./saved_models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6358dba",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa78a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architectures defined!\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN for MNIST and Fashion-MNIST\"\"\"\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*7*7 if input_channels==1 else 64*8*8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "def get_resnet18(num_classes=10):\n",
    "    \"\"\"ResNet18 adapted for CIFAR-10\"\"\"\n",
    "    model = torchvision.models.resnet18(pretrained=False)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "print(\"Model architectures defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e44867",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3fe33cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions defined!\n"
     ]
    }
   ],
   "source": [
    "def model_to_vector(model):\n",
    "    \"\"\"Convert model parameters to a flat numpy vector\"\"\"\n",
    "    return torch.cat([p.detach().flatten() for p in model.parameters()]).cpu().numpy()\n",
    "\n",
    "def vector_to_model(model, vec):\n",
    "    \"\"\"Load vector into model parameters\"\"\"\n",
    "    ptr = 0\n",
    "    for p in model.parameters():\n",
    "        num = p.numel()\n",
    "        p.data.copy_(torch.tensor(vec[ptr:ptr+num]).view_as(p.data))\n",
    "        ptr += num\n",
    "\n",
    "def subtract_model_params(m_new, m_old):\n",
    "    \"\"\"Compute parameter update: new - old\"\"\"\n",
    "    v_new = model_to_vector(m_new)\n",
    "    v_old = model_to_vector(m_old)\n",
    "    return v_new - v_old\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(\"Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcda00",
   "metadata": {},
   "source": [
    "## Attack Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf8a2037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack functions defined!\n"
     ]
    }
   ],
   "source": [
    "def sign_flip_update(grad_vec):\n",
    "    \"\"\"Sign flipping attack: negate the gradient update\"\"\"\n",
    "    return -grad_vec\n",
    "\n",
    "def lie_attack_simulation(global_mean, global_std, beta=1.5):\n",
    "    \"\"\"LIE attack: craft malicious update near mean but in negative direction\"\"\"\n",
    "    sign = -1.0\n",
    "    return global_mean + sign * beta * global_std\n",
    "\n",
    "print(\"Attack functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c19f5",
   "metadata": {},
   "source": [
    "## Federated Learning Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8850675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning functions defined!\n"
     ]
    }
   ],
   "source": [
    "def local_train(model, train_loader, device, epochs=1, lr=0.01):\n",
    "    \"\"\"Train model locally for specified epochs\"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def fedavg(models):\n",
    "    \"\"\"Federated Averaging: average model parameters\"\"\"\n",
    "    avg = {}\n",
    "    for k in models[0].keys():\n",
    "        avg[k] = sum([m[k].float() for m in models]) / len(models)\n",
    "    return avg\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"Evaluate model accuracy on test set\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "print(\"Federated learning functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82090b",
   "metadata": {},
   "source": [
    "## NC-FLD Defense: Weight Pruning, PCA, and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551c1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC-FLD defense functions defined!\n"
     ]
    }
   ],
   "source": [
    "def select_top_by_magnitude(grad_vec, keep_ratio):\n",
    "    \"\"\"Select top parameters by magnitude (weight pruning step)\"\"\"\n",
    "    magnitudes = np.abs(grad_vec)\n",
    "    threshold = np.quantile(magnitudes, 1 - keep_ratio)\n",
    "    mask = magnitudes > threshold\n",
    "    return grad_vec[mask], mask\n",
    "\n",
    "def build_feature_matrix(selected_vectors):\n",
    "    \"\"\"Build feature matrix from selected parameters (pad to max length)\"\"\"\n",
    "    max_len = max([v.shape[0] for v in selected_vectors])\n",
    "    X = np.zeros((len(selected_vectors), max_len), dtype=np.float32)\n",
    "    for i, v in enumerate(selected_vectors):\n",
    "        X[i, :v.shape[0]] = v\n",
    "    return X\n",
    "\n",
    "def apply_pca(X, n_components=2):\n",
    "    \"\"\"Apply PCA for dimensionality reduction\"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    Z = pca.fit_transform(X)\n",
    "    return Z, pca\n",
    "\n",
    "def classify_embeddings(Z, method='ocsvm'):\n",
    "    \"\"\"Classify clients as benign (True) or malicious (False)\"\"\"\n",
    "    if method == 'ocsvm':\n",
    "        clf = OneClassSVM(kernel='rbf', nu=0.1, gamma='scale')\n",
    "        clf.fit(Z)\n",
    "        preds = clf.predict(Z)  # +1 inlier, -1 outlier\n",
    "        return (preds == 1).astype(bool)\n",
    "    \n",
    "    elif method == 'agg':\n",
    "        cl = AgglomerativeClustering(n_clusters=2, linkage='average')\n",
    "        labels = cl.fit_predict(Z)\n",
    "        counts = np.bincount(labels)\n",
    "        benign_label = np.argmax(counts)\n",
    "        return (labels == benign_label).astype(bool)\n",
    "    \n",
    "    elif method == 'knn':\n",
    "        k = 4\n",
    "        kn = KNeighborsClassifier(n_neighbors=k, metric='manhattan')\n",
    "        agg = AgglomerativeClustering(n_clusters=2)\n",
    "        pseudo = agg.fit_predict(Z)\n",
    "        counts = np.bincount(pseudo)\n",
    "        benign_label = np.argmax(counts)\n",
    "        y = (pseudo == benign_label).astype(int)\n",
    "        kn.fit(Z, y)\n",
    "        preds = kn.predict(Z)\n",
    "        return (preds == 1).astype(bool)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'Unknown defense method: {method}')\n",
    "\n",
    "print(\"NC-FLD defense functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bab89f",
   "metadata": {},
   "source": [
    "## Main Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22f6c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation function defined!\n"
     ]
    }
   ],
   "source": [
    "# Create named tuple for experiment configuration\n",
    "ExpConfig = namedtuple('ExpConfig', ['dataset', 'clients', 'rounds', 'local_epochs', \n",
    "                                     'lr', 'attack', 'malicious_ratio', 'defense', \n",
    "                                     'keep_ratio', 'seed', 'log_interval'])\n",
    "\n",
    "def simulate(config):\n",
    "    \"\"\"\n",
    "    Run federated learning simulation with NC-FLD defense\n",
    "    \n",
    "    Args:\n",
    "        config: ExpConfig object with experiment parameters\n",
    "    \n",
    "    Returns:\n",
    "        results: List of test accuracies per round\n",
    "    \"\"\"\n",
    "    # Device setup - TPU first, then CUDA, then CPU\n",
    "    try:\n",
    "        if TPU_AVAILABLE:\n",
    "            device = xm.xla_device()\n",
    "            print(f\"Using TPU device: {device}\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            print(\"Using CUDA device\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print(\"Using CPU device\")\n",
    "    except:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "    \n",
    "    set_seed(config.seed)\n",
    "    \n",
    "    # Create directory for this experiment's models\n",
    "    exp_name = f\"{config.dataset}_{config.attack}_ratio{config.malicious_ratio}_{config.defense}\"\n",
    "    model_dir = os.path.join('saved_models', exp_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Dataset setup\n",
    "    if config.dataset == 'mnist':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.5,), (0.5,))])\n",
    "        trainset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                             download=True, transform=transform)\n",
    "        testset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "                                            download=True, transform=transform)\n",
    "        model_fn = lambda: SimpleCNN(input_channels=1, num_classes=10)\n",
    "        batch_size = 32\n",
    "        flip_map = {7: 1}\n",
    "    \n",
    "    elif config.dataset == 'fmnist':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.5,), (0.5,))])\n",
    "        trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, \n",
    "                                                     download=True, transform=transform)\n",
    "        testset = torchvision.datasets.FashionMNIST(root='./data', train=False, \n",
    "                                                    download=True, transform=transform)\n",
    "        model_fn = lambda: SimpleCNN(input_channels=1, num_classes=10)\n",
    "        batch_size = 25\n",
    "        flip_map = {0: 6, 6: 0}\n",
    "    \n",
    "    elif config.dataset == 'cifar10':\n",
    "        transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                          (0.5, 0.5, 0.5))])\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                               download=True, transform=transform)\n",
    "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                              download=True, transform=transform)\n",
    "        model_fn = lambda: get_resnet18(num_classes=10)\n",
    "        batch_size = 100\n",
    "        flip_map = {5: 3}  # dog -> cat\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError(f'Dataset {config.dataset} not implemented')\n",
    "    \n",
    "    # Create client data shards\n",
    "    total_train = len(trainset)\n",
    "    indices = list(range(total_train))\n",
    "    random.shuffle(indices)\n",
    "    shards = np.array_split(indices, config.clients)\n",
    "    \n",
    "    client_loaders = []\n",
    "    for s in shards:\n",
    "        sub = Subset(trainset, s)\n",
    "        loader = DataLoader(sub, batch_size=batch_size, shuffle=True)\n",
    "        client_loaders.append(loader)\n",
    "    \n",
    "    testloader = DataLoader(testset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # Select malicious clients\n",
    "    num_mal = int(config.malicious_ratio * config.clients)\n",
    "    mal_indices = set(random.sample(range(config.clients), num_mal))\n",
    "    print(f\"Malicious clients: {sorted(list(mal_indices))} (count={num_mal})\")\n",
    "    \n",
    "    # Initialize global model\n",
    "    global_model = model_fn().to(device)\n",
    "    global_state = copy.deepcopy(global_model.state_dict())\n",
    "    \n",
    "    # Main federated learning rounds\n",
    "    results = []\n",
    "    for r in trange(config.rounds, desc='Training Rounds'):\n",
    "        local_states = []\n",
    "        grad_vectors = []\n",
    "        raw_masks = []\n",
    "        \n",
    "        # Local training for each client\n",
    "        for c in range(config.clients):\n",
    "            model_c = model_fn().to(device)\n",
    "            model_c.load_state_dict(global_state)\n",
    "            old_model = copy.deepcopy(model_c)\n",
    "            \n",
    "            # Label flip attack: poison training data\n",
    "            if config.attack == 'label_flip' and c in mal_indices:\n",
    "                ds_indices = shards[c]\n",
    "                poison_list = []\n",
    "                for idx in ds_indices:\n",
    "                    x, y = trainset[idx]\n",
    "                    y_ = flip_map.get(int(y), int(y))\n",
    "                    poison_list.append((x, y_))\n",
    "                poisoned_loader = DataLoader(poison_list, batch_size=batch_size, shuffle=True)\n",
    "                local_train(model_c, poisoned_loader, device, \n",
    "                          epochs=config.local_epochs, lr=config.lr)\n",
    "            else:\n",
    "                local_train(model_c, client_loaders[c], device, \n",
    "                          epochs=config.local_epochs, lr=config.lr)\n",
    "            \n",
    "            # Compute update vector\n",
    "            diff_vec = subtract_model_params(model_c, old_model)\n",
    "            \n",
    "            # Model poisoning attacks\n",
    "            if c in mal_indices and config.attack == 'sign_flip':\n",
    "                diff_vec = sign_flip_update(diff_vec)\n",
    "            \n",
    "            if c in mal_indices and config.attack == 'lie':\n",
    "                if len(grad_vectors) > 0:\n",
    "                    global_mean = np.mean(np.stack(grad_vectors), axis=0)\n",
    "                    global_std = np.std(np.stack(grad_vectors), axis=0) + 1e-6\n",
    "                    diff_vec = lie_attack_simulation(global_mean, global_std, beta=1.0)\n",
    "                else:\n",
    "                    diff_vec = sign_flip_update(diff_vec)\n",
    "            \n",
    "            grad_vectors.append(diff_vec)\n",
    "            local_states.append(model_c.state_dict())\n",
    "        \n",
    "        # Synchronize if using TPU\n",
    "        if TPU_AVAILABLE:\n",
    "            xm.mark_step()\n",
    "        \n",
    "        # NC-FLD Defense: Weight Pruning\n",
    "        selected_vecs = []\n",
    "        for vec in grad_vectors:\n",
    "            sel, mask = select_top_by_magnitude(vec, config.keep_ratio)\n",
    "            selected_vecs.append(sel)\n",
    "            raw_masks.append(mask)\n",
    "        \n",
    "        # Build feature matrix and apply PCA\n",
    "        X = build_feature_matrix(selected_vecs)\n",
    "        Z, pca = apply_pca(X, n_components=2)\n",
    "        \n",
    "        # Classify clients\n",
    "        benign_mask = classify_embeddings(Z, method=config.defense)\n",
    "        benign_indices = [i for i, b in enumerate(benign_mask) if b]\n",
    "        \n",
    "        if len(benign_indices) == 0:\n",
    "            print(\"Warning: all clients classified malicious; skipping aggregation\")\n",
    "            continue\n",
    "        \n",
    "        # Aggregate benign clients (FedAvg)\n",
    "        benign_states = [local_states[i] for i in benign_indices]\n",
    "        new_global_state = fedavg(benign_states)\n",
    "        global_state = new_global_state\n",
    "        \n",
    "        # Evaluate\n",
    "        global_model.load_state_dict(global_state)\n",
    "        acc = evaluate(global_model, testloader, device)\n",
    "        results.append(acc)\n",
    "        \n",
    "        if (r + 1) % config.log_interval == 0:\n",
    "            print(f\"Round {r+1}/{config.rounds} - Test Acc: {acc:.4f} - \"\n",
    "                  f\"Included: {len(benign_indices)}/{config.clients}\")\n",
    "    \n",
    "    final_acc = results[-1] if len(results) > 0 else None\n",
    "    print(f\"Final test accuracy: {final_acc:.4f}\")\n",
    "    \n",
    "    # Save only the final model after all rounds complete\n",
    "    # Move model to CPU before saving to ensure compatibility\n",
    "    cpu_global_state = {k: v.cpu() for k, v in global_state.items()}\n",
    "    \n",
    "    torch.save({\n",
    "        'round': config.rounds,\n",
    "        'model_state_dict': cpu_global_state,\n",
    "        'config': config._asdict(),\n",
    "        'accuracy': final_acc,\n",
    "        'all_round_accuracies': results,\n",
    "        'malicious_clients': list(mal_indices)\n",
    "    }, os.path.join(model_dir, f'model_final_round_{config.rounds}.pt'))\n",
    "    \n",
    "    print(f\"Final model saved to: {model_dir}/model_final_round_{config.rounds}.pt\")\n",
    "    return results, final_acc\n",
    "\n",
    "print(\"Simulation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae0e2a",
   "metadata": {},
   "source": [
    "## Model Loading Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e6848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading utility defined!\n"
     ]
    }
   ],
   "source": [
    "def load_saved_model(model_path, dataset='fmnist'):\n",
    "    \"\"\"\n",
    "    Load a saved model checkpoint\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model file\n",
    "        dataset: Dataset name to initialize correct model architecture\n",
    "    \n",
    "    Returns:\n",
    "        model: Loaded model\n",
    "        checkpoint: Full checkpoint dictionary with metadata\n",
    "    \"\"\"\n",
    "    # Initialize model architecture\n",
    "    if dataset in ['mnist', 'fmnist']:\n",
    "        model = SimpleCNN(input_channels=1, num_classes=10)\n",
    "    elif dataset == 'cifar10':\n",
    "        model = get_resnet18(num_classes=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Loaded model from round {checkpoint['round']}\")\n",
    "    if checkpoint['accuracy'] is not None:\n",
    "        print(f\"Accuracy: {checkpoint['accuracy']:.4f}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "# Example usage:\n",
    "# model, checkpoint = load_saved_model('saved_models/fmnist_label_flip_ratio0.1_ocsvm/model_round_100.pt', dataset='fmnist')\n",
    "\n",
    "print(\"Model loading utility defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee2433",
   "metadata": {},
   "source": [
    "## Initialize Results Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a25d381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results storage initialized!\n"
     ]
    }
   ],
   "source": [
    "# Storage for all experiment results\n",
    "all_results = []\n",
    "\n",
    "print(\"Results storage initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d9bc4",
   "metadata": {},
   "source": [
    "---\n",
    "# Fashion-MNIST Experiments (100 clients)\n",
    "## All Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f05c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious clients: [5, 8, 20, 41, 54, 59, 72, 80, 83, 84] (count=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:   0%|          | 0/100 [00:05<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m defense \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mocsvm\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33magg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mknn\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      5\u001b[39m     config = ExpConfig(dataset=\u001b[33m'\u001b[39m\u001b[33mfmnist\u001b[39m\u001b[33m'\u001b[39m, clients=\u001b[32m100\u001b[39m, rounds=\u001b[32m100\u001b[39m, local_epochs=\u001b[32m1\u001b[39m, lr=\u001b[32m0.01\u001b[39m,\n\u001b[32m      6\u001b[39m                        attack=attack, malicious_ratio=ratio, defense=defense,\n\u001b[32m      7\u001b[39m                        keep_ratio=\u001b[32m0.15\u001b[39m, seed=\u001b[32m42\u001b[39m, log_interval=\u001b[32m10\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     round_accs, final_acc = \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     all_results.append({\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfmnist\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mattack\u001b[39m\u001b[33m'\u001b[39m: attack, \u001b[33m'\u001b[39m\u001b[33mmalicious_ratio\u001b[39m\u001b[33m'\u001b[39m: ratio,\n\u001b[32m     10\u001b[39m                        \u001b[33m'\u001b[39m\u001b[33mdefense\u001b[39m\u001b[33m'\u001b[39m: defense, \u001b[33m'\u001b[39m\u001b[33mfinal_accuracy\u001b[39m\u001b[33m'\u001b[39m: final_acc, \u001b[33m'\u001b[39m\u001b[33mround_accuracies\u001b[39m\u001b[33m'\u001b[39m: round_accs})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36msimulate\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    107\u001b[39m     local_train(model_c, poisoned_loader, device, \n\u001b[32m    108\u001b[39m               epochs=config.local_epochs, lr=config.lr)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[43mlocal_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Compute update vector\u001b[39;00m\n\u001b[32m    114\u001b[39m diff_vec = subtract_model_params(model_c, old_model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mlocal_train\u001b[39m\u001b[34m(model, train_loader, device, epochs, lr)\u001b[39m\n\u001b[32m     11\u001b[39m out = model(x)\n\u001b[32m     12\u001b[39m loss = criterion(out, y)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Fashion-MNIST - All Attacks, Ratios, and Defenses\n",
    "for attack in ['label_flip', 'sign_flip', 'lie']:\n",
    "    for ratio in [0.1, 0.2, 0.3, 0.4]:\n",
    "        for defense in ['ocsvm', 'agg', 'knn']:\n",
    "            config = ExpConfig(dataset='fmnist', clients=100, rounds=100, local_epochs=1, lr=0.01,\n",
    "                               attack=attack, malicious_ratio=ratio, defense=defense,\n",
    "                               keep_ratio=0.15, seed=42, log_interval=10)\n",
    "            round_accs, final_acc = simulate(config)\n",
    "            all_results.append({'dataset': 'fmnist', 'attack': attack, 'malicious_ratio': ratio,\n",
    "                               'defense': defense, 'final_accuracy': final_acc, 'round_accuracies': round_accs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5c2e3",
   "metadata": {},
   "source": [
    "## Check Existing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c203aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHECKING EXISTING TRAINED MODELS\n",
      "================================================================================\n",
      "\n",
      "Found 32 trained models:\n",
      "--------------------------------------------------------------------------------\n",
      "1. fmnist_lie_ratio0.3_agg\n",
      "   Round: 100, Accuracy: 0.8323\n",
      "   Path: saved_models/fmnist_lie_ratio0.3_agg/model_final_round_100.pt\n",
      "\n",
      "2. fmnist_lie_ratio0.1_knn\n",
      "   Round: 100, Accuracy: 0.8324\n",
      "   Path: saved_models/fmnist_lie_ratio0.1_knn/model_final_round_100.pt\n",
      "\n",
      "3. fmnist_lie_ratio0.2_agg\n",
      "   Round: 100, Accuracy: 0.8321\n",
      "   Path: saved_models/fmnist_lie_ratio0.2_agg/model_final_round_100.pt\n",
      "\n",
      "4. fmnist_lie_ratio0.2_knn\n",
      "   Round: 100, Accuracy: 0.8321\n",
      "   Path: saved_models/fmnist_lie_ratio0.2_knn/model_final_round_100.pt\n",
      "\n",
      "5. fmnist_lie_ratio0.1_agg\n",
      "   Round: 100, Accuracy: 0.8323\n",
      "   Path: saved_models/fmnist_lie_ratio0.1_agg/model_final_round_100.pt\n",
      "\n",
      "6. fmnist_sign_flip_ratio0.4_agg\n",
      "   Round: 100, Accuracy: 0.8324\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.4_agg/model_final_round_100.pt\n",
      "\n",
      "7. fmnist_sign_flip_ratio0.4_knn\n",
      "   Round: 100, Accuracy: 0.8317\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.4_knn/model_final_round_100.pt\n",
      "\n",
      "8. fmnist_sign_flip_ratio0.3_agg\n",
      "   Round: 100, Accuracy: 0.8327\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.3_agg/model_final_round_100.pt\n",
      "\n",
      "9. fmnist_sign_flip_ratio0.1_knn\n",
      "   Round: 100, Accuracy: 0.8322\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.1_knn/model_final_round_100.pt\n",
      "\n",
      "10. fmnist_sign_flip_ratio0.2_agg\n",
      "   Round: 100, Accuracy: 0.8325\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.2_agg/model_final_round_100.pt\n",
      "\n",
      "11. fmnist_sign_flip_ratio0.2_knn\n",
      "   Round: 100, Accuracy: 0.8318\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.2_knn/model_final_round_100.pt\n",
      "\n",
      "12. fmnist_sign_flip_ratio0.3_knn\n",
      "   Round: 100, Accuracy: 0.8331\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.3_knn/model_final_round_100.pt\n",
      "\n",
      "13. fmnist_sign_flip_ratio0.1_agg\n",
      "   Round: 100, Accuracy: 0.8331\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.1_agg/model_final_round_100.pt\n",
      "\n",
      "14. fmnist_sign_flip_ratio0.1_ocsvm\n",
      "   Round: 100, Accuracy: 0.8324\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.1_ocsvm/model_final_round_100.pt\n",
      "\n",
      "15. fmnist_label_flip_ratio0.2_ocsvm\n",
      "   Round: 100, Accuracy: 0.8306\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.2_ocsvm/model_final_round_100.pt\n",
      "\n",
      "16. fmnist_sign_flip_ratio0.3_ocsvm\n",
      "   Round: 100, Accuracy: 0.8328\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.3_ocsvm/model_final_round_100.pt\n",
      "\n",
      "17. fmnist_lie_ratio0.2_ocsvm\n",
      "   Round: 100, Accuracy: 0.8322\n",
      "   Path: saved_models/fmnist_lie_ratio0.2_ocsvm/model_final_round_100.pt\n",
      "\n",
      "18. fmnist_label_flip_ratio0.4_ocsvm\n",
      "   Round: 100, Accuracy: 0.8091\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.4_ocsvm/model_final_round_100.pt\n",
      "\n",
      "19. fmnist_sign_flip_ratio0.2_ocsvm\n",
      "   Round: 100, Accuracy: 0.8326\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.2_ocsvm/model_final_round_100.pt\n",
      "\n",
      "20. fmnist_label_flip_ratio0.3_ocsvm\n",
      "   Round: 100, Accuracy: 0.8256\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.3_ocsvm/model_final_round_100.pt\n",
      "\n",
      "21. fmnist_label_flip_ratio0.3_agg\n",
      "   Round: 100, Accuracy: 0.8316\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.3_agg/model_final_round_100.pt\n",
      "\n",
      "22. fmnist_label_flip_ratio0.1_knn\n",
      "   Round: 100, Accuracy: 0.8321\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.1_knn/model_final_round_100.pt\n",
      "\n",
      "23. fmnist_label_flip_ratio0.2_agg\n",
      "   Round: 100, Accuracy: 0.8310\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.2_agg/model_final_round_100.pt\n",
      "\n",
      "24. fmnist_lie_ratio0.3_ocsvm\n",
      "   Round: 100, Accuracy: 0.8329\n",
      "   Path: saved_models/fmnist_lie_ratio0.3_ocsvm/model_final_round_100.pt\n",
      "\n",
      "25. fmnist_lie_ratio0.1_ocsvm\n",
      "   Round: 100, Accuracy: 0.8323\n",
      "   Path: saved_models/fmnist_lie_ratio0.1_ocsvm/model_final_round_100.pt\n",
      "\n",
      "26. fmnist_label_flip_ratio0.2_knn\n",
      "   Round: 100, Accuracy: 0.8319\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.2_knn/model_final_round_100.pt\n",
      "\n",
      "27. fmnist_label_flip_ratio0.1_ocsvm\n",
      "   Round: 100, Accuracy: 0.8315\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.1_ocsvm/model_final_round_100.pt\n",
      "\n",
      "28. fmnist_label_flip_ratio0.3_knn\n",
      "   Round: 100, Accuracy: 0.8321\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.3_knn/model_final_round_100.pt\n",
      "\n",
      "29. fmnist_label_flip_ratio0.1_agg\n",
      "   Round: 100, Accuracy: 0.8316\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.1_agg/model_final_round_100.pt\n",
      "\n",
      "30. fmnist_sign_flip_ratio0.4_ocsvm\n",
      "   Round: 100, Accuracy: 0.8322\n",
      "   Path: saved_models/fmnist_sign_flip_ratio0.4_ocsvm/model_final_round_100.pt\n",
      "\n",
      "31. fmnist_label_flip_ratio0.4_agg\n",
      "   Round: 100, Accuracy: 0.8323\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.4_agg/model_final_round_100.pt\n",
      "\n",
      "32. fmnist_label_flip_ratio0.4_knn\n",
      "   Round: 100, Accuracy: 0.8322\n",
      "   Path: saved_models/fmnist_label_flip_ratio0.4_knn/model_final_round_100.pt\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def check_model_exists(dataset, attack, ratio, defense, rounds=100):\n",
    "    \"\"\"Check if a trained model already exists\"\"\"\n",
    "    exp_name = f\"{dataset}_{attack}_ratio{ratio}_{defense}\"\n",
    "    model_path = os.path.join('saved_models', exp_name, f'model_final_round_{rounds}.pt')\n",
    "    return os.path.exists(model_path), model_path\n",
    "\n",
    "def get_trained_models_info():\n",
    "    \"\"\"Get information about all trained models\"\"\"\n",
    "    trained_models = []\n",
    "    \n",
    "    if not os.path.exists('saved_models'):\n",
    "        return trained_models\n",
    "    \n",
    "    for exp_dir in os.listdir('saved_models'):\n",
    "        exp_path = os.path.join('saved_models', exp_dir)\n",
    "        if os.path.isdir(exp_path):\n",
    "            # Look for final model files\n",
    "            for file in os.listdir(exp_path):\n",
    "                if file.startswith('model_final_round_') and file.endswith('.pt'):\n",
    "                    model_path = os.path.join(exp_path, file)\n",
    "                    try:\n",
    "                        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                        trained_models.append({\n",
    "                            'experiment': exp_dir,\n",
    "                            'round': checkpoint['round'],\n",
    "                            'accuracy': checkpoint.get('accuracy', 'N/A'),\n",
    "                            'path': model_path,\n",
    "                            'config': checkpoint.get('config', {})\n",
    "                        })\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    return trained_models\n",
    "\n",
    "# Check what models are already trained\n",
    "print(\"=\"*80)\n",
    "print(\"CHECKING EXISTING TRAINED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trained_models = get_trained_models_info()\n",
    "\n",
    "if len(trained_models) == 0:\n",
    "    print(\"\\nNo trained models found. All experiments will be run.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(trained_models)} trained models:\")\n",
    "    print(\"-\"*80)\n",
    "    for i, model in enumerate(trained_models, 1):\n",
    "        print(f\"{i}. {model['experiment']}\")\n",
    "        acc = model['accuracy']\n",
    "        if isinstance(acc, float):\n",
    "            print(f\"   Round: {model['round']}, Accuracy: {acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"   Round: {model['round']}, Accuracy: {acc}\")\n",
    "        print(f\"   Path: {model['path']}\")\n",
    "        print()\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954843a1",
   "metadata": {},
   "source": [
    "## Smart Training: Skip Already Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17a0af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FASHION-MNIST EXPERIMENTS - SMART TRAINING\n",
      "================================================================================\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.1_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8315\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.1_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8316\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.1_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8321\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.2_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8306\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.2_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8310\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.2_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8319\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.3_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8256\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.3_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8316\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.3_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8321\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.4_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8091\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.4_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8323\n",
      "\n",
      "✓ SKIPPING: fmnist_label_flip_ratio0.4_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8322\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.1_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8324\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.1_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8331\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.1_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8322\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.2_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8326\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.2_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8325\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.2_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8318\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.3_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8328\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.3_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8327\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.3_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8331\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.4_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8322\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.4_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8324\n",
      "\n",
      "✓ SKIPPING: fmnist_sign_flip_ratio0.4_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8317\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.1_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8323\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.1_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8323\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.1_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8324\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.2_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8322\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.2_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8321\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.2_knn (already trained)\n",
      "  Loaded: Accuracy = 0.8321\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.3_ocsvm (already trained)\n",
      "  Loaded: Accuracy = 0.8329\n",
      "\n",
      "✓ SKIPPING: fmnist_lie_ratio0.3_agg (already trained)\n",
      "  Loaded: Accuracy = 0.8323\n",
      "\n",
      "→ TRAINING: fmnist_lie_ratio0.3_knn\n",
      "Using CPU device\n",
      "Malicious clients: [5, 8, 9, 10, 12, 15, 20, 23, 33, 35, 41, 42, 43, 54, 59, 60, 65, 66, 69, 71, 72, 76, 78, 80, 83, 84, 86, 91, 92, 97] (count=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  10%|█         | 10/100 [03:00<26:37, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 10/100 - Test Acc: 0.7233 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  20%|██        | 20/100 [06:02<24:25, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 20/100 - Test Acc: 0.7575 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  30%|███       | 30/100 [08:56<20:01, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 30/100 - Test Acc: 0.7708 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  40%|████      | 40/100 [11:47<17:19, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 40/100 - Test Acc: 0.7830 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  50%|█████     | 50/100 [14:49<15:42, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 50/100 - Test Acc: 0.7935 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  60%|██████    | 60/100 [17:51<12:00, 18.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 60/100 - Test Acc: 0.8043 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  70%|███████   | 70/100 [20:56<08:59, 17.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 70/100 - Test Acc: 0.8123 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  80%|████████  | 80/100 [23:50<05:47, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 80/100 - Test Acc: 0.8213 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  90%|█████████ | 90/100 [26:44<02:54, 17.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 90/100 - Test Acc: 0.8281 - Included: 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds: 100%|██████████| 100/100 [29:39<00:00, 17.79s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 100/100 - Test Acc: 0.8322 - Included: 70/100\n",
      "Final test accuracy: 0.8322\n",
      "Final model saved to: saved_models/fmnist_lie_ratio0.3_knn/model_final_round_100.pt\n",
      "\n",
      "→ TRAINING: fmnist_lie_ratio0.4_ocsvm\n",
      "Using CPU device\n",
      "Malicious clients: [5, 8, 9, 10, 11, 12, 15, 20, 23, 32, 33, 34, 35, 36, 38, 41, 42, 43, 54, 55, 59, 60, 61, 64, 65, 66, 68, 69, 71, 72, 76, 78, 80, 83, 84, 86, 90, 91, 92, 97] (count=40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  10%|█         | 10/100 [03:06<27:48, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 10/100 - Test Acc: 0.7272 - Included: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  20%|██        | 20/100 [06:30<26:54, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 20/100 - Test Acc: 0.7575 - Included: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  30%|███       | 30/100 [09:38<21:33, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 30/100 - Test Acc: 0.7705 - Included: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  40%|████      | 40/100 [12:40<18:18, 18.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 40/100 - Test Acc: 0.7842 - Included: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  50%|█████     | 50/100 [15:46<15:21, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 50/100 - Test Acc: 0.7958 - Included: 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  60%|██████    | 60/100 [19:14<15:33, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 60/100 - Test Acc: 0.8070 - Included: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  70%|███████   | 70/100 [22:58<10:57, 21.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 70/100 - Test Acc: 0.8133 - Included: 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  80%|████████  | 80/100 [26:32<06:54, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 80/100 - Test Acc: 0.8210 - Included: 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  90%|█████████ | 90/100 [29:55<03:21, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 90/100 - Test Acc: 0.8273 - Included: 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds: 100%|██████████| 100/100 [33:20<00:00, 20.01s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 100/100 - Test Acc: 0.8329 - Included: 92/100\n",
      "Final test accuracy: 0.8329\n",
      "Final model saved to: saved_models/fmnist_lie_ratio0.4_ocsvm/model_final_round_100.pt\n",
      "\n",
      "→ TRAINING: fmnist_lie_ratio0.4_agg\n",
      "Using CPU device\n",
      "Malicious clients: [5, 8, 9, 10, 11, 12, 15, 20, 23, 32, 33, 34, 35, 36, 38, 41, 42, 43, 54, 55, 59, 60, 61, 64, 65, 66, 68, 69, 71, 72, 76, 78, 80, 83, 84, 86, 90, 91, 92, 97] (count=40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  10%|█         | 10/100 [03:33<31:14, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 10/100 - Test Acc: 0.7243 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  20%|██        | 20/100 [07:04<30:04, 22.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 20/100 - Test Acc: 0.7540 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  30%|███       | 30/100 [10:30<23:11, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 30/100 - Test Acc: 0.7702 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  40%|████      | 40/100 [14:04<20:53, 20.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 40/100 - Test Acc: 0.7831 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  50%|█████     | 50/100 [17:37<17:13, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 50/100 - Test Acc: 0.7934 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  60%|██████    | 60/100 [21:15<13:54, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 60/100 - Test Acc: 0.8037 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  70%|███████   | 70/100 [24:40<10:32, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 70/100 - Test Acc: 0.8115 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  80%|████████  | 80/100 [28:45<08:39, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 80/100 - Test Acc: 0.8198 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  90%|█████████ | 90/100 [33:38<04:33, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 90/100 - Test Acc: 0.8277 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds: 100%|██████████| 100/100 [37:22<00:00, 22.42s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 100/100 - Test Acc: 0.8323 - Included: 60/100\n",
      "Final test accuracy: 0.8323\n",
      "Final model saved to: saved_models/fmnist_lie_ratio0.4_agg/model_final_round_100.pt\n",
      "\n",
      "→ TRAINING: fmnist_lie_ratio0.4_knn\n",
      "Using CPU device\n",
      "Malicious clients: [5, 8, 9, 10, 11, 12, 15, 20, 23, 32, 33, 34, 35, 36, 38, 41, 42, 43, 54, 55, 59, 60, 61, 64, 65, 66, 68, 69, 71, 72, 76, 78, 80, 83, 84, 86, 90, 91, 92, 97] (count=40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  10%|█         | 10/100 [03:46<33:57, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 10/100 - Test Acc: 0.7242 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  20%|██        | 20/100 [07:35<30:06, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 20/100 - Test Acc: 0.7543 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  30%|███       | 30/100 [11:24<26:48, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 30/100 - Test Acc: 0.7701 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  40%|████      | 40/100 [15:12<23:16, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 40/100 - Test Acc: 0.7831 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  50%|█████     | 50/100 [19:10<19:19, 23.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 50/100 - Test Acc: 0.7933 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  60%|██████    | 60/100 [23:04<15:26, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 60/100 - Test Acc: 0.8039 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  70%|███████   | 70/100 [26:55<11:17, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 70/100 - Test Acc: 0.8118 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  80%|████████  | 80/100 [30:42<07:29, 22.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 80/100 - Test Acc: 0.8196 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds:  90%|█████████ | 90/100 [34:25<03:46, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 90/100 - Test Acc: 0.8278 - Included: 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Rounds: 100%|██████████| 100/100 [38:14<00:00, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 100/100 - Test Acc: 0.8324 - Included: 60/100\n",
      "Final test accuracy: 0.8324\n",
      "Final model saved to: saved_models/fmnist_lie_ratio0.4_knn/model_final_round_100.pt\n",
      "\n",
      "================================================================================\n",
      "FASHION-MNIST EXPERIMENTS SUMMARY\n",
      "================================================================================\n",
      "Total experiments: 36\n",
      "Skipped (already trained): 32\n",
      "Newly trained: 4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fashion-MNIST - All Attacks, Ratios, and Defenses (Skip if already trained)\n",
    "print(\"=\"*80)\n",
    "print(\"FASHION-MNIST EXPERIMENTS - SMART TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_experiments = 0\n",
    "skipped_experiments = 0\n",
    "trained_experiments = 0\n",
    "\n",
    "for attack in ['label_flip', 'sign_flip', 'lie']:\n",
    "    for ratio in [0.1, 0.2, 0.3, 0.4]:\n",
    "        for defense in ['ocsvm', 'agg', 'knn']:\n",
    "            total_experiments += 1\n",
    "            \n",
    "            # Check if model already exists\n",
    "            exists, model_path = check_model_exists('fmnist', attack, ratio, defense, rounds=100)\n",
    "            \n",
    "            if exists:\n",
    "                print(f\"\\n✓ SKIPPING: fmnist_{attack}_ratio{ratio}_{defense} (already trained)\")\n",
    "                skipped_experiments += 1\n",
    "                \n",
    "                # Load existing results\n",
    "                try:\n",
    "                    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                    final_acc = checkpoint.get('accuracy')\n",
    "                    round_accs = checkpoint.get('all_round_accuracies', [])\n",
    "                    \n",
    "                    all_results.append({\n",
    "                        'dataset': 'fmnist', \n",
    "                        'attack': attack, \n",
    "                        'malicious_ratio': ratio,\n",
    "                        'defense': defense, \n",
    "                        'final_accuracy': final_acc, \n",
    "                        'round_accuracies': round_accs\n",
    "                    })\n",
    "                    print(f\"  Loaded: Accuracy = {final_acc:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Warning: Could not load checkpoint - {e}\")\n",
    "            else:\n",
    "                print(f\"\\n→ TRAINING: fmnist_{attack}_ratio{ratio}_{defense}\")\n",
    "                trained_experiments += 1\n",
    "                \n",
    "                config = ExpConfig(\n",
    "                    dataset='fmnist', \n",
    "                    clients=100, \n",
    "                    rounds=100, \n",
    "                    local_epochs=1, \n",
    "                    lr=0.01,\n",
    "                    attack=attack, \n",
    "                    malicious_ratio=ratio, \n",
    "                    defense=defense,\n",
    "                    keep_ratio=0.15, \n",
    "                    seed=42, \n",
    "                    log_interval=10\n",
    "                )\n",
    "                \n",
    "                round_accs, final_acc = simulate(config)\n",
    "                \n",
    "                all_results.append({\n",
    "                    'dataset': 'fmnist', \n",
    "                    'attack': attack, \n",
    "                    'malicious_ratio': ratio,\n",
    "                    'defense': defense, \n",
    "                    'final_accuracy': final_acc, \n",
    "                    'round_accuracies': round_accs\n",
    "                })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASHION-MNIST EXPERIMENTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total experiments: {total_experiments}\")\n",
    "print(f\"Skipped (already trained): {skipped_experiments}\")\n",
    "print(f\"Newly trained: {trained_experiments}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f47b91",
   "metadata": {},
   "source": [
    "## Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51b4191f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create pivot table for easy viewing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m summary_pivot = \u001b[43mdf\u001b[49m.pivot_table(\n\u001b[32m      3\u001b[39m     values=\u001b[33m'\u001b[39m\u001b[33mfinal_accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     index=[\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mattack\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmalicious_ratio\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      5\u001b[39m     columns=\u001b[33m'\u001b[39m\u001b[33mdefense\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     aggfunc=\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSUMMARY: Final Test Accuracy by Configuration\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Create pivot table for easy viewing\n",
    "summary_pivot = df.pivot_table(\n",
    "    values='final_accuracy',\n",
    "    index=['dataset', 'attack', 'malicious_ratio'],\n",
    "    columns='defense',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Final Test Accuracy by Configuration\")\n",
    "print(\"=\"*80)\n",
    "print(summary_pivot.to_string())\n",
    "\n",
    "summary_pivot.to_csv('summary_accuracy_table.csv')\n",
    "summary_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb35f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual dataset tables\n",
    "for dataset in df['dataset'].unique():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{dataset.upper()} - Detailed Results\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    df_dataset = df[df['dataset'] == dataset]\n",
    "    pivot = df_dataset.pivot_table(\n",
    "        values='final_accuracy',\n",
    "        index=['attack', 'malicious_ratio'],\n",
    "        columns='defense',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    print(pivot.to_string())\n",
    "    pivot.to_csv(f'{dataset}_results_table.csv')\n",
    "    display(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0616aa",
   "metadata": {},
   "source": [
    "## Visualization 1: Accuracy vs Malicious Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f93f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy vs malicious ratio\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "fig.suptitle('NC-FLD Defense Performance: Accuracy vs Malicious Ratio', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "datasets = df['dataset'].unique()\n",
    "attacks = df['attack'].unique()\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, attack in enumerate(attacks):\n",
    "        ax = axes[i, j]\n",
    "        data = df[(df['dataset'] == dataset) & (df['attack'] == attack)]\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            for defense in ['ocsvm', 'agg', 'knn']:\n",
    "                defense_data = data[data['defense'] == defense].sort_values('malicious_ratio')\n",
    "                if len(defense_data) > 0:\n",
    "                    ax.plot(defense_data['malicious_ratio'], \n",
    "                           defense_data['final_accuracy'],\n",
    "                           marker='o', label=defense.upper(), linewidth=2.5, markersize=8)\n",
    "            \n",
    "            ax.set_xlabel('Malicious Client Ratio', fontsize=11)\n",
    "            ax.set_ylabel('Test Accuracy', fontsize=11)\n",
    "            ax.set_title(f'{dataset.upper()} - {attack.replace(\"_\", \" \").title()}', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "            ax.legend(fontsize=10)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_vs_malicious_ratio.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5b9bd",
   "metadata": {},
   "source": [
    "## Visualization 2: Defense Method Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ec8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot comparing defense methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Average Defense Performance by Dataset', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    ax = axes[i]\n",
    "    data = df[df['dataset'] == dataset]\n",
    "    defense_avg = data.groupby('defense')['final_accuracy'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "    bars = ax.bar(range(len(defense_avg)), defense_avg.values, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax.set_xticks(range(len(defense_avg)))\n",
    "    ax.set_xticklabels([d.upper() for d in defense_avg.index], fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Average Test Accuracy', fontsize=12)\n",
    "    ax.set_title(f'{dataset.upper()}', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "               f'{height:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('defense_method_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa5400",
   "metadata": {},
   "source": [
    "## Visualization 3: Attack Impact Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap showing attack impact\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Attack Impact on Accuracy (Averaged Across Defenses)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    ax = axes[i]\n",
    "    data = df[df['dataset'] == dataset]\n",
    "    \n",
    "    heatmap_data = data.pivot_table(\n",
    "        values='final_accuracy',\n",
    "        index='attack',\n",
    "        columns='malicious_ratio',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                vmin=0, vmax=1, ax=ax, cbar_kws={'label': 'Accuracy'},\n",
    "                linewidths=0.5, linecolor='gray')\n",
    "    ax.set_title(f'{dataset.upper()}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Malicious Ratio', fontsize=11)\n",
    "    ax.set_ylabel('Attack Type', fontsize=11)\n",
    "    ax.set_yticklabels([a.replace('_', ' ').title() for a in heatmap_data.index], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('attack_impact_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e061c3",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Overall Accuracy Statistics:\")\n",
    "print(df['final_accuracy'].describe())\n",
    "\n",
    "print(\"\\n2. Best Performing Configurations (Top 10):\")\n",
    "top_10 = df.nlargest(10, 'final_accuracy')[['dataset', 'attack', 'malicious_ratio', 'defense', 'final_accuracy']]\n",
    "print(top_10.to_string(index=False))\n",
    "\n",
    "print(\"\\n3. Worst Performing Configurations (Bottom 10):\")\n",
    "bottom_10 = df.nsmallest(10, 'final_accuracy')[['dataset', 'attack', 'malicious_ratio', 'defense', 'final_accuracy']]\n",
    "print(bottom_10.to_string(index=False))\n",
    "\n",
    "print(\"\\n4. Average Accuracy by Defense Method:\")\n",
    "defense_stats = df.groupby('defense')['final_accuracy'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(defense_stats.to_string())\n",
    "\n",
    "print(\"\\n5. Average Accuracy by Attack Type:\")\n",
    "attack_stats = df.groupby('attack')['final_accuracy'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(attack_stats.to_string())\n",
    "\n",
    "print(\"\\n6. Average Accuracy by Dataset:\")\n",
    "dataset_stats = df.groupby('dataset')['final_accuracy'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(dataset_stats.to_string())\n",
    "\n",
    "print(\"\\n7. Average Accuracy by Malicious Ratio:\")\n",
    "ratio_stats = df.groupby('malicious_ratio')['final_accuracy'].agg(['mean', 'std', 'min', 'max'])\n",
    "print(ratio_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511dec4",
   "metadata": {},
   "source": [
    "## Generate Comprehensive Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769466c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive text report\n",
    "with open('nc_fld_experiment_report.txt', 'w') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"NC-FLD FEDERATED LEARNING DEFENSE\\n\")\n",
    "    f.write(\"COMPREHENSIVE EXPERIMENT REPORT\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Total Experiments Completed: {len(df)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"OVERALL SUMMARY TABLE\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(summary_pivot.to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"{dataset.upper()} DETAILED RESULTS\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        df_dataset = df[df['dataset'] == dataset]\n",
    "        pivot = df_dataset.pivot_table(\n",
    "            values='final_accuracy',\n",
    "            index=['attack', 'malicious_ratio'],\n",
    "            columns='defense',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        f.write(pivot.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"KEY FINDINGS\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    best_defense = df.groupby('defense')['final_accuracy'].mean().idxmax()\n",
    "    best_defense_acc = df.groupby('defense')['final_accuracy'].mean().max()\n",
    "    f.write(f\"Best Defense Method: {best_defense.upper()} (Avg Accuracy: {best_defense_acc:.4f})\\n\")\n",
    "    \n",
    "    most_robust = df.groupby('attack')['final_accuracy'].mean().idxmax()\n",
    "    f.write(f\"Most Robust Against: {most_robust.replace('_', ' ').title()} Attack\\n\")\n",
    "    \n",
    "    best_dataset = df.groupby('dataset')['final_accuracy'].mean().idxmax()\n",
    "    f.write(f\"Best Dataset Performance: {best_dataset.upper()}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  1. nc_fld_experiment_results.csv - Raw results data\")\n",
    "print(\"  2. summary_accuracy_table.csv - Summary pivot table\")\n",
    "print(\"  3. mnist_results_table.csv - MNIST detailed results\")\n",
    "print(\"  4. fmnist_results_table.csv - Fashion-MNIST detailed results\")\n",
    "print(\"  5. cifar10_results_table.csv - CIFAR-10 detailed results\")\n",
    "print(\"  6. accuracy_vs_malicious_ratio.png - Line plots\")\n",
    "print(\"  7. defense_method_comparison.png - Bar charts\")\n",
    "print(\"  8. attack_impact_heatmap.png - Heatmaps\")\n",
    "print(\"  9. nc_fld_experiment_report.txt - Comprehensive text report\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f7fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
